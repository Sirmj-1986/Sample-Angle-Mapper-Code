{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sirmj-1986/Sample-Angle-Mapper-Code/blob/main/CKI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s-CZH2Cm18t",
        "outputId": "f5fad95b-8236-453d-a96d-4cdbf676d53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.4)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting earthpy\n",
            "  Downloading earthpy-0.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (from earthpy) (1.1.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from earthpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from earthpy) (2.0.2)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (from earthpy) (1.4.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from earthpy) (0.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from earthpy) (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->earthpy) (2.9.0.post0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas->earthpy) (0.11.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas->earthpy) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from geopandas->earthpy) (3.7.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas->earthpy) (2.1.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (8.2.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio->earthpy) (1.1.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->earthpy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->earthpy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->earthpy) (2.5.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->earthpy) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->earthpy) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->earthpy) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->earthpy) (2025.9.9)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->earthpy) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas->earthpy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->earthpy) (1.17.0)\n",
            "Downloading earthpy-0.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: earthpy\n",
            "Successfully installed earthpy-0.9.4\n"
          ]
        }
      ],
      "source": [
        "# Install some packages\n",
        "!pip install rasterio\n",
        "!pip install earthpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0-IOvHYrnVSS"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import earthpy.plot as ep\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "W4XFBF8BnVHw",
        "outputId": "199fa51b-02d5-4616-bcc8-3141fe79b926"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3793592510.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhsRdSV3qv8p"
      },
      "outputs": [],
      "source": [
        "# Define path that contains the datasets\n",
        "Sample_Path = '/content/drive/MyDrive/GEE_Exports/Training_Samples_Fixed.csv'\n",
        "Image_Path = '/content/drive/MyDrive/GEE_Exports/ImageG_Stacked_Float.tif'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2iET2npnVEO"
      },
      "outputs": [],
      "source": [
        "# Define target and predictor variables\n",
        "Bands = ['PC2', 'PC3', 'PC5', 'geology','B09', 'B08', 'B07', 'B05', 'B06', 'B3N',\n",
        "  'Calcite_SAM', 'Kaolinite_SAM', 'IronOxide_SAM']  # Feature columns\n",
        "LC = ['class']\n",
        "Classes = [0, 1, 2, 3]\n",
        "N_Classes = 4\n",
        "Names = [\"No_Alteration\", \"Calcite\", \"Kaolinite\", \"IronOxide\"]\n",
        "Palette = [\n",
        "    '#008000',  # Green  for class 0 (No_Alteration)\n",
        "    '#FF0000',  # Red    for class 1 (Calcite)\n",
        "    '#0000FF',  # Blue   for class 2 (Kaolinite)\n",
        "    '#FFD700',  # Gold   for class 3 (IronOxide)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP8BRkZknU8n"
      },
      "outputs": [],
      "source": [
        "image = rasterio.open(Image_Path)\n",
        "\n",
        "band_count = image.count\n",
        "height = image.height\n",
        "width = image.width\n",
        "crs = image.crs\n",
        "transform = image.transform\n",
        "\n",
        "print(f\"Image has {band_count} bands.\")\n",
        "print(f\"Image dimensions: {height} rows x {width} columns\")\n",
        "print(f\"Coordinate Reference System (CRS): {crs}\")\n",
        "\n",
        "band_indices_for_vis = [Bands.index('Calcite_SAM') + 1, Bands.index('Kaolinite_SAM') + 1, Bands.index('IronOxide_SAM') + 1]\n",
        "\n",
        "image_vis = []\n",
        "for b_index in band_indices_for_vis:\n",
        "    image_vis.append(image.read(b_index))\n",
        "image_vis = np.stack(image_vis)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "ep.plot_rgb(\n",
        "    image_vis,\n",
        "    stretch=True\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5jW0OsnnU0k"
      },
      "outputs": [],
      "source": [
        "# Load training data as a DataFrame\n",
        "df = pd.read_csv(Sample_Path)\n",
        "\n",
        "# Inspect first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Separate features (X) and label (y)\n",
        "X = df[Bands]\n",
        "y = df['class']\n",
        "\n",
        "# Ensure no missing values\n",
        "print(f\"Missing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in label: {y.isnull().sum()}\")\n",
        "\n",
        "# Split into training and testing subsets\n",
        "# (you can also do cross-validation if you prefer)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpK861jnnUtP"
      },
      "outputs": [],
      "source": [
        "# Combine X_train with y_train for easy plotting\n",
        "df_train = X_train.copy()\n",
        "df_train['class'] = y_train.values\n",
        "\n",
        "# Set up the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a count plot of 'class' to show the distribution of training samples for each class\n",
        "sns.countplot(\n",
        "    x='class',        # The column on the x-axis\n",
        "    data=df_train,    # The DataFrame containing our features and labels\n",
        "    palette=Palette   # Use the predefined color palette for each class\n",
        ")\n",
        "\n",
        "# Add a title to the plot\n",
        "plt.title('Distribution of Samples Across Classes')\n",
        "\n",
        "# Label the x-axis\n",
        "plt.xlabel('Class')\n",
        "\n",
        "# Label the y-axis\n",
        "plt.ylabel('Number of Samples')\n",
        "\n",
        "# Customize the x-ticks to show class names instead of numbers\n",
        "plt.xticks(\n",
        "    ticks=[0, 1, 2, 3],                           # Positions for each class\n",
        "    labels=[\"No_Alteration\", \"Calcite\", \"Kaolinite\", \"IronOxide\"]\n",
        ")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6585i0a-nUlt"
      },
      "outputs": [],
      "source": [
        "# Combine X_train with y_train for easy plotting\n",
        "df_train = X_train.copy()\n",
        "df_train['class'] = y_train.values\n",
        "\n",
        "# Scatter plot of B4 vs B8, colored by 'class'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x='PC2',\n",
        "    y='PC3',\n",
        "    hue='class',\n",
        "    data=df_train,\n",
        "    palette=Palette\n",
        ")\n",
        "plt.title('Scatter Plot of PC2 vs PC3')\n",
        "plt.xlabel('PC2 reflectance')\n",
        "plt.ylabel('PC3 reflectance')\n",
        "plt.legend(title='Class')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o83dXnRSsop1"
      },
      "outputs": [],
      "source": [
        "g = sns.pairplot(df_train, vars=Bands, hue='class', palette=Palette)\n",
        "g.fig.suptitle('Pairwise Scatter Plots for All Bands', y=1.02)\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "    ax.set_xlabel(ax.get_xlabel(), fontsize=17, fontweight='bold')\n",
        "    ax.set_ylabel(ax.get_ylabel(), fontsize=17, fontweight='bold')\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc-9HLZosojg"
      },
      "outputs": [],
      "source": [
        "# Define the export path\n",
        "export_folder = '/content/drive/MyDrive/AGU'\n",
        "export_filename = 'Pairwise_Scatter_Plot222.png'\n",
        "export_path = os.path.join(export_folder, export_filename)\n",
        "\n",
        "if not os.path.exists(export_folder):\n",
        "    os.makedirs(export_folder)\n",
        "g.savefig(export_path, dpi=1000, bbox_inches='tight')\n",
        "\n",
        "print(f\"Pair plot exported successfully to: {export_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHJqTT2Ssoc4"
      },
      "outputs": [],
      "source": [
        "# Libraries needed\n",
        "from mpl_toolkits.mplot3d import Axes3D  # needed for 3D projections\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Create a color map from class labels to colors in the palette\n",
        "color_map = {class_label: Palette[i] for i, class_label in enumerate(Classes)}\n",
        "\n",
        "# Map each sample's class label to its corresponding color\n",
        "colors = df_train['class'].map(color_map)\n",
        "\n",
        "# Initialize the figure and 3D axis\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Scatter plot:\n",
        "#   x-axis => PC2 (Blue)\n",
        "#   y-axis => PC3 (Red)\n",
        "#   z-axis => PC5 (NIR)\n",
        "scatter = ax.scatter(\n",
        "    df_train['PC2'],\n",
        "    df_train['PC3'],\n",
        "    df_train['PC5'],\n",
        "    c=colors,\n",
        "    s=15  # point size (optional)\n",
        ")\n",
        "\n",
        "# Label the axes\n",
        "ax.set_xlabel('PC2)', labelpad=15)\n",
        "ax.set_ylabel('PC3', labelpad=15)\n",
        "ax.set_zlabel('PC5', labelpad=15)\n",
        "\n",
        "# Adjust distance of the \"camera\" to the plot (optional)\n",
        "ax.dist = 11\n",
        "\n",
        "# (Optional) Adjust the viewing angle for better orientation\n",
        "# ax.view_init(elev=20, azim=30)  # e.g., 20° above, 30° rotation\n",
        "\n",
        "# Create a custom legend\n",
        "legend_elements = [\n",
        "    Patch(facecolor=Palette[i], edgecolor='k', label=f'Class {Classes[i]}')\n",
        "    for i in range(len(Classes))\n",
        "]\n",
        "ax.legend(\n",
        "    handles=legend_elements,\n",
        "    title=\"Classes\",\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(1.05, 1)  # move legend outside the plot if you want\n",
        ")\n",
        "\n",
        "# Add a title\n",
        "plt.title('3D Scatter Plot of Blue, Red, and NIR Bands', pad=20)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXQ7fqWusoZG"
      },
      "outputs": [],
      "source": [
        "# Import TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# 1. Initialize the t-SNE model\n",
        "tsne = TSNE(\n",
        "    n_components=2,  # Project down to 2D\n",
        "    perplexity=30,   # Typical range is 5-50; tune as needed\n",
        "    random_state=42, # For reproducibility\n",
        "    n_iter=1000      # Number of gradient descent iterations\n",
        ")\n",
        "\n",
        "# 2. Fit and transform your feature matrix\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "# 3. Plot the results\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# color_map = {class_label: Palette[i] for i, class_label in enumerate(Classes)}\n",
        "colors = [color_map[label] for label in y]\n",
        "\n",
        "plt.scatter(\n",
        "    X_tsne[:, 0],  # t-SNE x-coordinates\n",
        "    X_tsne[:, 1],  # t-SNE y-coordinates\n",
        "    c=colors,\n",
        "    s=10,          # Marker size\n",
        "    alpha=0.7      # Transparency\n",
        ")\n",
        "\n",
        "plt.title(\"t-SNE Projection of Land Cover Samples\")\n",
        "plt.xlabel(\"t-SNE Dimension 1\")\n",
        "plt.ylabel(\"t-SNE Dimension 2\")\n",
        "\n",
        "# (Optional) Add a legend\n",
        "# If you have a legend, you can manually create it or use existing patches\n",
        "# or you can skip the legend if it becomes cluttered in high-dimensional data\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwcS8q39smWs"
      },
      "outputs": [],
      "source": [
        "# 1. Melt the DataFrame into a \"long\" format for box plotting\n",
        "df_melt = df_train.melt(\n",
        "    id_vars='class',               # Keep 'class' as an identifier\n",
        "    value_vars=Bands,              # The band columns to melt\n",
        "    var_name='Band',               # Name for the new \"band\" column\n",
        "    value_name='Reflectance'       # Name for the new \"reflectance\" column\n",
        ")\n",
        "\n",
        "# 2. Create a box plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(\n",
        "    x='Band',\n",
        "    y='Reflectance',\n",
        "    hue='class',\n",
        "    data=df_melt,\n",
        "    palette=Palette                # (Optional) use the predefined color palette\n",
        ")\n",
        "\n",
        "# 3. Customize the plot\n",
        "plt.title(\"Box Plots of Reflectance Values by Band and Class\")\n",
        "plt.xlabel(\"Spectral Band\")\n",
        "plt.ylabel(\"Reflectance Value\")\n",
        "plt.legend(title=\"Class\", loc=\"upper right\")\n",
        "\n",
        "# 4. Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7xUAZobWR3Q"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameter grid for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Define hyperparameter grid for SVM\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Define hyperparameter grid for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "print(\"Hyperparameter grids defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01daea1e"
      },
      "outputs": [],
      "source": [
        "# Random Forest Grid Search\n",
        "rf_grid_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid_rf,\n",
        "    cv=5\n",
        ")\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# SVM Grid Search\n",
        "svm_grid_search = GridSearchCV(\n",
        "    SVC(random_state=42, probability=True), # Add probability=True\n",
        "    param_grid_svm,\n",
        "    cv=5\n",
        ")\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# XGBoost Grid Search\n",
        "from xgboost import XGBClassifier # Import XGBClassifier\n",
        "\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=N_Classes,\n",
        "        eval_metric='mlogloss',\n",
        "        random_state=42\n",
        "    ),\n",
        "    param_grid_xgb,\n",
        "    cv=5\n",
        ")\n",
        "xgb_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Grid search for all models complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFpKbVEVWRzq"
      },
      "outputs": [],
      "source": [
        "# Get the best models from grid search\n",
        "best_rf = rf_grid_search.best_estimator_\n",
        "best_svm = svm_grid_search.best_estimator_\n",
        "best_xgb = xgb_grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best models\n",
        "rf_preds = best_rf.predict(X_test)\n",
        "svm_preds = best_svm.predict(X_test)\n",
        "xgb_preds = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate each model\n",
        "models = {\n",
        "    \"Random Forest\": rf_preds,\n",
        "    \"SVM\": svm_preds,\n",
        "    \"XGBoost\": xgb_preds\n",
        "}\n",
        "\n",
        "for name, preds in models.items():\n",
        "    print(f\"\\n** {name} **\")\n",
        "    print(\"Accuracy:\", (preds == y_test).mean())\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, preds, labels=Classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j-7RKFOdmR5"
      },
      "outputs": [],
      "source": [
        "# Read all bands as a NumPy array\n",
        "# shape = (band_count, height, width)\n",
        "img_array = image.read()\n",
        "\n",
        "# For example, if the image bands match the ordering of 'Bands' exactly,\n",
        "# index them accordingly. Make sure the array order aligns with your CSV.\n",
        "print(\"Image array shape:\", img_array.shape)  # Should be (#bands, height, width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Eth4SwWRvH"
      },
      "outputs": [],
      "source": [
        "# Transpose and reshape to [#pixels, #bands]\n",
        "# If img_array is [bands, rows, cols]:\n",
        "img_reshaped = img_array.reshape(band_count, -1).T  # shape => (rows*cols, bands)\n",
        "print(\"Reshaped array for prediction:\", img_reshaped.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCoUKV6aWRpW"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the entire image using each trained model\n",
        "rf_prediction = best_rf.predict(img_reshaped)\n",
        "svm_prediction = best_svm.predict(img_reshaped)\n",
        "xgb_prediction = best_xgb.predict(img_reshaped)\n",
        "\n",
        "print(\"Predictions made for all models on the image data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "434a49dc"
      },
      "outputs": [],
      "source": [
        "# 1. Make predictions on the test set\n",
        "rf_preds_tuned = best_rf.predict(X_test)\n",
        "svm_preds_tuned = best_svm.predict(X_test)\n",
        "xgb_preds_tuned = best_xgb.predict(X_test)\n",
        "\n",
        "# 2. Create a dictionary of tuned models and their predictions\n",
        "tuned_models = {\n",
        "    \"Tuned Random Forest\": rf_preds_tuned,\n",
        "    \"Tuned SVM\": svm_preds_tuned,\n",
        "    \"Tuned XGBoost\": xgb_preds_tuned\n",
        "}\n",
        "\n",
        "# 3. Iterate through the tuned models and evaluate performance\n",
        "for name, preds in tuned_models.items():\n",
        "    print(f\"\\n** {name} **\")\n",
        "    print(\"Accuracy:\", (preds == y_test).mean())\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test, preds, target_names=Names))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, preds, labels=Classes)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "    disp.plot(cmap='Blues')\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3qUNGbmWRle"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Patch\n",
        "import numpy as np # Ensure numpy is imported\n",
        "import matplotlib.pyplot as plt # Ensure matplotlib.pyplot is imported\n",
        "import rasterio.coords # Import rasterio.coords\n",
        "import os # Import os for path joining\n",
        "\n",
        "# Define the export folder\n",
        "export_folder = '/content/drive/MyDrive/AGU'\n",
        "\n",
        "# Create the export folder if it doesn't exist\n",
        "if not os.path.exists(export_folder):\n",
        "    os.makedirs(export_folder)\n",
        "\n",
        "# Prepare a discrete colormap\n",
        "# We need one more level than classes for from_levels_and_colors\n",
        "levels = Classes + [max(Classes) + 1]\n",
        "cmap, norm = from_levels_and_colors(levels, Palette)\n",
        "\n",
        "# Reshape predictions back to image dimensions\n",
        "rf_prediction_map = rf_prediction.reshape(height, width).astype(np.uint8)\n",
        "svm_prediction_map = svm_prediction.reshape(height, width).astype(np.uint8)\n",
        "xgb_prediction_map = xgb_prediction.reshape(height, width).astype(np.uint8)\n",
        "\n",
        "# Calculate extent using rasterio.coords.BoundingBox\n",
        "bbox = rasterio.coords.BoundingBox(\n",
        "    left=transform.c,\n",
        "    bottom=transform.f + transform.e * height,\n",
        "    right=transform.c + transform.a * width,\n",
        "    top=transform.f\n",
        ")\n",
        "extent = [bbox.left, bbox.right, bbox.bottom, bbox.top]\n",
        "\n",
        "# Visualize Random Forest prediction map\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(rf_prediction_map, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
        "ax.set_title(\"Random Forest Classification Map\", fontsize=12)\n",
        "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "cbar = fig.colorbar(im, ax=ax, shrink=0.7, orientation='horizontal', pad=0.1) # Add pad for spacing\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "# Define export path and save the figure\n",
        "export_filename_rf = 'RandomForest_Classification_Map.png'\n",
        "export_path_rf = os.path.join(export_folder, export_filename_rf)\n",
        "plt.savefig(export_path_rf, dpi=1000, bbox_inches='tight')\n",
        "print(f\"Random Forest classification map exported successfully to: {export_path_rf}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Visualize SVM prediction map\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(svm_prediction_map, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
        "ax.set_title(\"SVM Classification Map\", fontsize=12)\n",
        "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "cbar = fig.colorbar(im, ax=ax, shrink=0.7, orientation='horizontal', pad=0.1) # Add pad for spacing\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "# Define export path and save the figure\n",
        "export_filename_svm = 'SVM_Classification_Map.png'\n",
        "export_path_svm = os.path.join(export_folder, export_filename_svm)\n",
        "plt.savefig(export_path_svm, dpi=1000, bbox_inches='tight')\n",
        "print(f\"SVM classification map exported successfully to: {export_path_svm}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Visualize XGBoost prediction map\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(xgb_prediction_map, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
        "ax.set_title(\"XGBoost Classification Map\", fontsize=12)\n",
        "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "cbar = fig.colorbar(im, ax=ax, shrink=0.7, orientation='horizontal', pad=0.1) # Add pad for spacing\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "\n",
        "# Define export path and save the figure\n",
        "export_filename_xgb = 'XGBoost_Classification_Map.png'\n",
        "export_path_xgb = os.path.join(export_folder, export_filename_xgb)\n",
        "plt.savefig(export_path_xgb, dpi=1000, bbox_inches='tight')\n",
        "print(f\"XGBoost classification map exported successfully to: {export_path_xgb}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "\n",
        "# Define the path to the hillshade image\n",
        "Hillshade_Path = '/content/drive/MyDrive/GEE_Exports/Hillshade.tif'\n",
        "\n",
        "# Load the hillshade image\n",
        "try:\n",
        "    with rasterio.open(Hillshade_Path) as hillshade_image:\n",
        "        hillshade_array = hillshade_image.read(1) # Read the first band (assuming it's a single-band hillshade)\n",
        "        hillshade_extent = [hillshade_image.bounds.left, hillshade_image.bounds.right,\n",
        "                          hillshade_image.bounds.bottom, hillshade_image.bounds.top]\n",
        "except rasterio.errors.RasterioIOError:\n",
        "    print(f\"Error: Could not open or read the hillshade image at {Hillshade_Path}\")\n",
        "    hillshade_array = None\n",
        "\n",
        "if 'extent' not in locals():\n",
        "\n",
        "    bbox = rasterio.coords.BoundingBox(\n",
        "        left=transform.c,\n",
        "        bottom=transform.f + transform.e * height,\n",
        "        right=transform.c + transform.a * width,\n",
        "        top=transform.f\n",
        "    )\n",
        "    extent = [bbox.left, bbox.right, bbox.bottom, bbox.top]\n",
        "\n",
        "try:\n",
        "    rf_prediction_map = rf_prediction.reshape(height, width).astype(np.uint8)\n",
        "    svm_prediction_map = svm_prediction.reshape(height, width).astype(np.uint8)\n",
        "    xgb_prediction_map = xgb_prediction.reshape(height, width).astype(np.uint8)\n",
        "except NameError:\n",
        "    print(\"Error: Prediction maps (rf_prediction, svm_prediction, xgb_prediction) are not defined.\")\n",
        "    print(\"Please ensure the previous cells generating these predictions have been run.\")\n",
        "    rf_prediction_map = None\n",
        "    svm_prediction_map = None\n",
        "    xgb_prediction_map = None\n",
        "\n",
        "\n",
        "if hillshade_array is not None and rf_prediction_map is not None:\n",
        "    remaining_classes = [c for c in Classes if c != 0]\n",
        "    remaining_names = [Names[i] for i in remaining_classes]\n",
        "    remaining_palette = [Palette[i] for i in remaining_classes]\n",
        "\n",
        "    levels_remaining = remaining_classes + [max(remaining_classes) + 1]\n",
        "    cmap_remaining, norm_remaining = from_levels_and_colors(levels_remaining, remaining_palette)\n",
        "\n",
        "    mask_rf_no_alteration = (rf_prediction_map == 0)\n",
        "    mask_svm_no_alteration = (svm_prediction_map == 0)\n",
        "    mask_xgb_no_alteration = (xgb_prediction_map == 0)\n",
        "\n",
        "    rf_altered_map = rf_prediction_map.astype(float) # Convert to float to allow NaN\n",
        "    rf_altered_map[mask_rf_no_alteration] = np.nan\n",
        "\n",
        "    svm_altered_map = svm_prediction_map.astype(float)\n",
        "    svm_altered_map[mask_svm_no_alteration] = np.nan\n",
        "\n",
        "    xgb_altered_map = xgb_prediction_map.astype(float)\n",
        "    xgb_altered_map[mask_xgb_no_alteration] = np.nan\n",
        "\n",
        "\n",
        "    # --- Plotting ---\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper') # Plot hillshade first\n",
        "    im = ax.imshow(rf_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7) # Overlay altered map with transparency\n",
        "    ax.set_title(\"Random Forest Altered Areas on Hillshade\", fontsize=12)\n",
        "    ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "    ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "\n",
        "    # Create a custom legend for the remaining classes\n",
        "    legend_elements = [plt.matplotlib.patches.Patch(facecolor=remaining_palette[i],\n",
        "                                                    label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "    ax.legend(handles=legend_elements, title=\"Altered Classes\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "    plt.show()\n",
        "\n",
        "    # Visualize SVM altered map on hillshade\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper') # Plot hillshade first\n",
        "    im = ax.imshow(svm_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7) # Overlay altered map with transparency\n",
        "    ax.set_title(\"SVM Altered Areas on Hillshade\", fontsize=12)\n",
        "    ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "    ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "    # Create a custom legend for the remaining classes\n",
        "    legend_elements = [plt.matplotlib.patches.Patch(facecolor=remaining_palette[i],\n",
        "                                                    label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "    ax.legend(handles=legend_elements, title=\"Altered Classes\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "    plt.show()\n",
        "\n",
        "    # Visualize XGBoost altered map on hillshade\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper') # Plot hillshade first\n",
        "    im = ax.imshow(xgb_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7) # Overlay altered map with transparency\n",
        "    ax.set_title(\"XGBoost Altered Areas on Hillshade\", fontsize=12)\n",
        "    ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "    ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "    # Create a custom legend for the remaining classes\n",
        "    legend_elements = [plt.matplotlib.patches.Patch(facecolor=remaining_palette[i],\n",
        "                                                    label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "    ax.legend(handles=legend_elements, title=\"Altered Classes\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Cannot generate plots. Please check for errors in loading the hillshade or prediction maps.\")"
      ],
      "metadata": {
        "id": "J4Kl8ZXbcLgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_folder = '/content/drive/MyDrive/AGU'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "plt.savefig(f\"{output_folder}/RF_Altered_Areas.png\", dpi=1000, bbox_inches='tight')\n",
        "plt.savefig(f\"{output_folder}/SVM_Altered_Areas.png\", dpi=1000, bbox_inches='tight')\n",
        "plt.savefig(f\"{output_folder}/XGBoost_Altered_Areas.png\", dpi=1000, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "UOB5eBDTtLCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "output_folder = '/content/drive/MyDrive/AGU'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create figure with vertical layout\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 30), constrained_layout=True)\n",
        "\n",
        "# RF Plot\n",
        "axes[0].imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper')\n",
        "axes[0].imshow(rf_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7)\n",
        "axes[0].set_title(\"Random Forest\", fontsize=16)\n",
        "axes[0].set_xlabel(\"Longitude\")\n",
        "axes[0].set_ylabel(\"Latitude\")\n",
        "\n",
        "# SVM Plot\n",
        "axes[1].imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper')\n",
        "axes[1].imshow(svm_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7)\n",
        "axes[1].set_title(\"SVM\", fontsize=16)\n",
        "axes[1].set_xlabel(\"Longitude\")\n",
        "axes[1].set_ylabel(\"Latitude\")\n",
        "\n",
        "# XGBoost Plot\n",
        "axes[2].imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper')\n",
        "axes[2].imshow(xgb_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7)\n",
        "axes[2].set_title(\"XGBoost\", fontsize=16)\n",
        "axes[2].set_xlabel(\"Longitude\")\n",
        "axes[2].set_ylabel(\"Latitude\")\n",
        "\n",
        "# Create a single legend below the last plot\n",
        "legend_elements = [plt.matplotlib.patches.Patch(facecolor=remaining_palette[i],\n",
        "                                                label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "fig.legend(handles=legend_elements, title=\"Altered Classes\", loc='lower center',\n",
        "           bbox_to_anchor=(0.5, -0.02), ncol=len(remaining_classes), fontsize=10, title_fontsize=12)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.05)  # Tight spacing between maps\n",
        "plt.savefig(f\"{output_folder}/RF_SVM_XGB_Combined_Vertical_Legend.png\", dpi=1000, bbox_inches='tight')\n",
        "plt.close(fig)\n"
      ],
      "metadata": {
        "id": "wTaLmTEMxPPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOGOi_uFWRh1"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create an ensemble model using VotingClassifier\n",
        "# We will use the best trained models\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', best_rf),\n",
        "        ('svm', best_svm),\n",
        "        ('xgb', best_xgb)\n",
        "    ],\n",
        "    voting='hard'  # 'hard' voting uses predicted class labels\n",
        ")\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the ensemble model\n",
        "ensemble_preds = ensemble_model.predict(X_test)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "print(\"\\n** Ensemble Model (Voting) **\")\n",
        "print(\"Accuracy:\", (ensemble_preds == y_test).mean())\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_test, ensemble_preds, target_names=Names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, ensemble_preds, labels=Classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=Classes)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Ensemble Model (Voting) - Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pS_yfJrWRdP"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the entire image using the ensemble model\n",
        "ensemble_prediction = ensemble_model.predict(img_reshaped)\n",
        "\n",
        "# Reshape predictions back to image dimensions\n",
        "ensemble_prediction_map = ensemble_prediction.reshape(height, width).astype(np.uint8)\n",
        "\n",
        "# Calculate extent manually from transform and dimensions\n",
        "# The transform matrix is a Rasterio Affine object.\n",
        "# transform.c and transform.f are the x and y coordinates of the upper-left corner.\n",
        "# transform.a and transform.e are the pixel width and height.\n",
        "left = transform.c\n",
        "top = transform.f\n",
        "right = transform.c + transform.a * width\n",
        "bottom = transform.f + transform.e * height\n",
        "extent = [left, right, bottom, top]\n",
        "\n",
        "# Prepare a discrete colormap\n",
        "levels = Classes + [max(Classes) + 1]\n",
        "cmap, norm = from_levels_and_colors(levels, Palette)\n",
        "\n",
        "# Visualize Ensemble model prediction map\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "im = ax.imshow(ensemble_prediction_map, cmap=cmap, norm=norm, extent=extent, origin='upper')\n",
        "ax.set_title(\"Ensemble Model Classification Map\", fontsize=12)\n",
        "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "cbar = fig.colorbar(im, ax=ax, shrink=0.7, orientation='horizontal', pad=0.1) # Add pad for spacing\n",
        "tick_positions = [i + 0.5 for i in Classes]\n",
        "cbar.set_ticks(tick_positions)\n",
        "cbar.set_ticklabels(Names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5XKEWkCWRYd"
      },
      "outputs": [],
      "source": [
        "# Get feature importances from Random Forest\n",
        "rf_feature_importances = best_rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "rf_importance_df = pd.DataFrame({\n",
        "    'Feature': Bands,\n",
        "    'Importance': rf_feature_importances\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "rf_importance_df = rf_importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot Random Forest Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=rf_importance_df, palette='viridis')\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Get feature importances from XGBoost\n",
        "xgb_feature_importances = best_xgb.feature_importances_\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "xgb_importance_df = pd.DataFrame({\n",
        "    'Feature': Bands,\n",
        "    'Importance': xgb_feature_importances\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "xgb_importance_df = xgb_importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot XGBoost Feature Importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=xgb_importance_df, palette='viridis')\n",
        "plt.title('XGBoost Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                   CNN MODEL\n",
        "                   "
      ],
      "metadata": {
        "id": "6imOf0Toi46e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (if not installed)\n",
        "!pip install rasterio scikit-learn matplotlib tensorflow\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "Dcj4yuWajB79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "import os\n"
      ],
      "metadata": {
        "id": "7xmnpO07jFc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_Path = '/content/drive/MyDrive/GEE_Exports/Training_Samples_Fixed.csv'\n",
        "Image_Path = '/content/drive/MyDrive/GEE_Exports/ImageG_Stacked_Float.tif'\n",
        "\n",
        "# Define target and predictor variables\n",
        "Bands = ['PC2', 'PC3', 'PC5', 'geology','B09', 'B08', 'B07', 'B05', 'B06', 'B3N',\n",
        "  'Calcite_SAM', 'Kaolinite_SAM', 'IronOxide_SAM']\n",
        "Classes = [0, 1, 2, 3]\n",
        "N_Classes = 4\n",
        "Names = [\"No_Alteration\", \"Calcite\", \"Kaolinite\", \"IronOxide\"]\n",
        "Palette = [\n",
        "    '#008000',  # Green  for class 0 (No_Alteration)\n",
        "    '#FF0000',  # Red    for class 1 (Calcite)\n",
        "    '#0000FF',  # Blue   for class 2 (Kaolinite)\n",
        "    '#FFD700',  # Gold   for class 3 (IronOxide)\n",
        "]\n",
        "Target = 'class'\n",
        "\n",
        "# Encode target classes\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df[Target])\n",
        "\n",
        "# Determine the number of unique classes\n",
        "num_unique_classes = df['label'].nunique()\n",
        "\n",
        "# Normalize input\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(df[Bands])\n",
        "# Fix: Change num_classes to the actual number of unique classes\n",
        "y = tf.keras.utils.to_categorical(df['label'], num_classes=num_unique_classes)\n",
        "\n",
        "# Reshape for CNN\n",
        "X = X.reshape(-1, 1, 1, len(Bands))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Ad4VSCCajGid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model building function for KerasTuner\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(filters=hp.Int('filters', 32, 128, step=32),\n",
        "                            kernel_size=(1, 1),\n",
        "                            activation='relu',\n",
        "                            input_shape=(1, 1, len(Bands))))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(filters=hp.Int('filters_2', 64, 256, step=64), # Add a second Conv2D layer\n",
        "                            kernel_size=(1, 1),\n",
        "                            activation='relu',\n",
        "                            kernel_regularizer=regularizers.l2(hp.Float('l2_reg', 0.0001, 0.01, sampling='log')))) # Tune L2 regularization\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units=hp.Int('units', 32, 128, step=32), activation='relu'))\n",
        "    model.add(layers.Dropout(rate=hp.Float('dropout', 0.2, 0.5, step=0.1)))\n",
        "    model.add(layers.Dense(num_unique_classes, activation='softmax'))  # Use the determined number of unique classes\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('lr', [1e-3, 1e-4, 1e-5])), # Tune learning rate\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = kt.RandomSearch(build_model,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=10,  # Reduced trials for faster execution\n",
        "                        executions_per_trial=1,\n",
        "                        directory='alteration_tuning_cnn',\n",
        "                        project_name='cnn_hyperparam_search')\n",
        "\n",
        "# Run search\n",
        "print(\"Starting hyperparameter search...\")\n",
        "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, verbose=1) # Increased epochs for better tuning\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "print(\"\\nEvaluating the best model on the test data...\")\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Ut7gZnjxjO3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "MOABBBq_jT1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(64, (1, 1), activation='relu', input_shape=(1, 1, len(Bands))),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(num_unique_classes, activation='softmax')  # Use the determined number of unique classes\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ZtOQkiSejmdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/PCalcite'\n",
        "\n",
        "# Accuracy plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('CNN Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(f'{save_path}/cnn_accuracy.png', dpi=1000)\n",
        "plt.show()\n",
        "\n",
        "# Loss plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('CNN Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(f'{save_path}/cnn_loss.png', dpi=1000)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hYvT_fvbjxVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=le.classes_,\n",
        "            yticklabels=le.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "htX_F69cj1lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the stacked raster\n",
        "with rasterio.open(Image_Path) as src:\n",
        "    img = src.read().astype('float32')\n",
        "    profile = src.profile\n",
        "\n",
        "# Normalize the image using same scaler\n",
        "img_reshaped = img.reshape(img.shape[0], -1).T\n",
        "img_scaled = scaler.transform(img_reshaped)\n",
        "img_scaled = img_scaled.reshape(-1, 1, 1, len(Bands))\n",
        "\n",
        "# Predict class for each pixel\n",
        "predictions = model.predict(img_scaled)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "pred_map = predicted_classes.reshape(profile['height'], profile['width'])\n",
        "\n",
        "# Export classified image\n",
        "out_path = f\"{save_path}/Predicted_Map_CNN.tif\"\n",
        "profile.update(dtype=rasterio.uint8, count=1)\n",
        "with rasterio.open(out_path, 'w', **profile) as dst:\n",
        "    dst.write(pred_map.astype(rasterio.uint8), 1)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(pred_map, cmap='viridis')\n",
        "plt.title(\"CNN\")\n",
        "plt.axis('off')\n",
        "plt.savefig(f'{save_path}/Predicted_Map_CNN.png', dpi=1000)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fsTU729Cj4tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ItoBu3BlJQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1JRdZ-snY-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wl4Q0kKFnY7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAtlneR8nY2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47AWcezenYyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Define the path to the hillshade image\n",
        "Hillshade_Path = '/content/drive/MyDrive/GEE_Exports/Hillshade.tif'\n",
        "\n",
        "# Load the hillshade image\n",
        "try:\n",
        "    with rasterio.open(Hillshade_Path) as hillshade_image:\n",
        "        hillshade_array = hillshade_image.read(1) # Read the first band (assuming it's a single-band hillshade)\n",
        "        hillshade_extent = [hillshade_image.bounds.left, hillshade_image.bounds.right,\n",
        "                          hillshade_image.bounds.bottom, hillshade_image.bounds.top]\n",
        "except rasterio.errors.RasterioIOError:\n",
        "    print(f\"Error: Could not open or read the hillshade image at {Hillshade_Path}\")\n",
        "    hillshade_array = None\n",
        "\n",
        "# Ensure the extent of the classification maps matches the hillshade for overlay\n",
        "# Use the extent calculated from the classification image's transform\n",
        "# (Assuming the classification image and hillshade have the same extent and resolution)\n",
        "# If not, resampling or reprojecting might be necessary.\n",
        "# For this code, we will assume the extents align.\n",
        "if 'extent' not in locals(): # Check if extent from classification map loading is defined\n",
        "    # If not defined, calculate it from the loaded classification image (from cell RP8BRkZknU8n)\n",
        "    # Need access to 'transform', 'height', 'width' from previous cells\n",
        "    try:\n",
        "        bbox = rasterio.coords.BoundingBox(\n",
        "            left=transform.c,\n",
        "            bottom=transform.f + transform.e * height,\n",
        "            right=transform.c + transform.a * width,\n",
        "            top=transform.f\n",
        "        )\n",
        "        extent = [bbox.left, bbox.right, bbox.bottom, bbox.top]\n",
        "    except NameError:\n",
        "        print(\"Error: 'transform', 'height', or 'width' not defined. Cannot calculate extent.\")\n",
        "        extent = None\n",
        "\n",
        "\n",
        "# Reshape predictions back to image dimensions (ensure these variables are available)\n",
        "# ensemble_prediction and predicted_classes (for CNN) should be available from previous cells\n",
        "try:\n",
        "    if 'ensemble_prediction' not in locals():\n",
        "        print(\"Error: 'ensemble_prediction' is not defined. Please run the cell that generates ensemble predictions.\")\n",
        "        ensemble_prediction_map = None\n",
        "    else:\n",
        "        ensemble_prediction_map = ensemble_prediction.reshape(height, width).astype(np.uint8)\n",
        "\n",
        "    if 'predicted_classes' not in locals():\n",
        "        print(\"Error: 'predicted_classes' (CNN) is not defined. Please run the cell that generates CNN predictions.\")\n",
        "        cnn_prediction_map = None\n",
        "    else:\n",
        "        cnn_prediction_map = predicted_classes.reshape(height, width).astype(np.uint8)\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: 'height' or 'width' not defined. Cannot reshape prediction maps.\")\n",
        "    ensemble_prediction_map = None\n",
        "    cnn_prediction_map = None\n",
        "\n",
        "\n",
        "if hillshade_array is not None and extent is not None:\n",
        "    # Prepare a discrete colormap (excluding No_Alteration class 0)\n",
        "    # We need one more level than classes for from_levels_and_colors for the remaining classes\n",
        "    remaining_classes = [c for c in Classes if c != 0]\n",
        "    remaining_names = [Names[i] for i in remaining_classes]\n",
        "    remaining_palette = [Palette[i] for i in remaining_classes]\n",
        "\n",
        "    # Adjust levels and colormap for the remaining classes\n",
        "    # Levels should span from the minimum remaining class value to max remaining class value + 1\n",
        "    levels_remaining = remaining_classes + [max(remaining_classes) + 1]\n",
        "    cmap_remaining, norm_remaining = from_levels_and_colors(levels_remaining, remaining_palette)\n",
        "\n",
        "\n",
        "    # --- Masking and Plotting ---\n",
        "\n",
        "    if ensemble_prediction_map is not None:\n",
        "        # Create mask for the 'No_Alteration' class (class 0) for Ensemble\n",
        "        mask_ensemble_no_alteration = (ensemble_prediction_map == 0)\n",
        "\n",
        "        # Apply mask to keep only the altered classes, setting masked values to NaN\n",
        "        ensemble_altered_map = ensemble_prediction_map.astype(float) # Convert to float to allow NaN\n",
        "        ensemble_altered_map[mask_ensemble_no_alteration] = np.nan\n",
        "\n",
        "        # Visualize Ensemble altered map on hillshade using the provided template\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        ax.imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper') # Plot hillshade first\n",
        "        im = ax.imshow(ensemble_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7) # Overlay altered map with transparency\n",
        "        ax.set_title(\"Ensemble Model Altered Areas on Hillshade\", fontsize=12)\n",
        "        ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "        ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "\n",
        "        # Create a custom legend for the remaining classes\n",
        "        legend_elements = [Patch(facecolor=remaining_palette[i],\n",
        "                                                        label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "        ax.legend(handles=legend_elements, title=\"Altered Classes\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    if cnn_prediction_map is not None:\n",
        "         # Create mask for the 'No_Alteration' class (class 0) for CNN\n",
        "        mask_cnn_no_alteration = (cnn_prediction_map == 0)\n",
        "\n",
        "        # Apply mask to keep only the altered classes, setting masked values to NaN\n",
        "        cnn_altered_map = cnn_prediction_map.astype(float) # Convert to float to allow NaN\n",
        "        cnn_altered_map[mask_cnn_no_alteration] = np.nan\n",
        "\n",
        "        # Visualize CNN altered map on hillshade using the provided template\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        ax.imshow(hillshade_array, cmap='gray', extent=hillshade_extent, origin='upper') # Plot hillshade first\n",
        "        im = ax.imshow(cnn_altered_map, cmap=cmap_remaining, norm=norm_remaining, extent=extent, origin='upper', alpha=0.7) # Overlay altered map with transparency\n",
        "        ax.set_title(\"CNN Altered Areas on Hillshade\", fontsize=12)\n",
        "        ax.set_xlabel(\"Longitude\", fontsize=12)\n",
        "        ax.set_ylabel(\"Latitude\", fontsize=12)\n",
        "\n",
        "        # Create a custom legend for the remaining classes\n",
        "        legend_elements = [Patch(facecolor=remaining_palette[i],\n",
        "                                                        label=remaining_names[i]) for i in range(len(remaining_classes))]\n",
        "        ax.legend(handles=legend_elements, title=\"Altered Classes\", loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "elif hillshade_array is None:\n",
        "    print(\"Cannot generate plots because the hillshade image could not be loaded.\")\n",
        "else:\n",
        "     print(\"Cannot generate plots because prediction maps or extent could not be determined.\")"
      ],
      "metadata": {
        "id": "PgFJeTXtnYpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4kIPFa5_r6rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MAz7d8hwPfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wye3WXG0wPa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcskYJvCwPWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPR8m0fawPRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ab1f9uEmwPL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP7cYO0fJ+zYBINbJY0lv/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}